{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.MichelleHottingerAssignment_regression_classification_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michhottinger/DS-Unit-2-Linear-Models/blob/master/4_MichelleHottingerAssignment_regression_classification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5bUOrwrKm4A",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [ ] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [ ] Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "- [ ] Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYFVCglSKm4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "#df = pd.read_csv(DATA_PATH+'burritos/Burrito - 10D.csv')\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPf1D5cIKm4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi086mJiKm4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R9q8emfKm4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfwB2tGLKm4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr7eJFiSKm4X",
        "colab_type": "code",
        "outputId": "313001c7-073b-419a-9d02-5e21471e296a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "df.head(40)\n",
        "df.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(421, 59)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnX2ogGXLcr0",
        "colab_type": "code",
        "outputId": "fe0ce9a9-686e-41e3-957f-43cf33ad3418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#converted date to date.time format and create a test, val and train set\n",
        "#can use: from sklearn.model_selection import train_test_split\n",
        "#train, val = train_test_split(train, random_state=42)\n",
        "#train.shape, val.shape\n",
        "\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "train = df[df.Date.dt.year <= 2016]\n",
        "val = df[df.Date.dt.year == 2017]\n",
        "test = df[df.Date.dt.year >= 2018]\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 59), (85, 59), (38, 59))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTfUMwAZLcoj",
        "colab_type": "code",
        "outputId": "1962a80b-eadc-44f0-cce3-526b9a05c2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "val.shape, test.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((85, 59), (38, 59))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVECw5TELcjy",
        "colab_type": "code",
        "outputId": "a056b25e-1a89-482a-b222-d70268e9baf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#Assume baseline that all burritos are 'great' or better\n",
        "target = 'Great'\n",
        "y_train = train[target]\n",
        "y_val = val[target]\n",
        "y_test = test[target]\n",
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.590604\n",
              "True     0.409396\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXBa-HTRPtf3",
        "colab_type": "text"
      },
      "source": [
        "40% of the time, burritos are great while our majority class is 59% they are not great. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGfINF1Lcbs",
        "colab_type": "code",
        "outputId": "1480690a-daee-4146-a156-d85c4c7169fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#prediction model needs to beat %59 not great\n",
        "#I'll shoe this in another way below\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "majority_class = y_train.mode()[0]\n",
        "y_pred = [majority_class] * len(y_train)\n",
        "\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5906040268456376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKmjaTcVgqn6",
        "colab_type": "code",
        "outputId": "339073ff-11c0-4683-ad07-b1edfd1f5224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>2016-01-18</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>California</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asada</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>California</td>\n",
              "      <td>2016-01-27</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Burrito       Date  Yelp  Google Chips  ...  Sushi  Avocado  Corn  Zucchini  Great\n",
              "0  California 2016-01-18   3.5     4.2   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "1  California 2016-01-24   3.5     3.3   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "2    Carnitas 2016-01-24   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "3       Asada 2016-01-24   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "4  California 2016-01-27   4.0     3.8     x  ...    NaN      NaN   NaN       NaN   True\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDIn-aOLcNl",
        "colab_type": "code",
        "outputId": "a646fe0a-c5a3-4703-a3ae-c7a544449cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#import the model and go\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "import category_encoders as ce\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#3. Arrange the X features and y vectors(see above) and impute data\n",
        "#prep the dataset by dropping the target column\n",
        "#set the target and features\n",
        "\n",
        "#target = 'Great'\n",
        "#cardi = ['ADDRESS', 'LAND_SQUARE_FEET', 'SALE_DATE', 'BUILDING_CLASS_AT_PRESENT', 'BUILDING_CLASS_AT_TIME_OF_SALE', 'EASE-MENT', 'APARTMENT_NUMBER', 'TAX_CLASS_AT_TIME_OF_SALE']\n",
        "#features = train.columns.drop([target] + cardi)\n",
        "\n",
        "features = ['Hunger', 'Volume', 'Tortilla', 'Temp', 'Meat', 'Fillings', 'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap']\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "X_train.shape\n",
        "\n",
        "\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(298, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQSQm62NpE6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "26db327e-739b-47fe-dcb1-3695a26f746a"
      },
      "source": [
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "X_train_encoded.head()\n",
        "X_train.isnull().sum()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Hunger            1\n",
              "Volume          124\n",
              "Tortilla          0\n",
              "Temp             15\n",
              "Meat             10\n",
              "Fillings          1\n",
              "Meat:filling      6\n",
              "Uniformity        2\n",
              "Salsa            20\n",
              "Synergy           2\n",
              "Wrap              2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwxTXNqhbwTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#impute missing values\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxs_Y-_Gkemx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale them\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo6YQW7Lbf80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "99c55db8-81ba-4bf1-bdd8-5c12c2b51a84"
      },
      "source": [
        "# 4. Fit the model Logistic Regression\n",
        "\n",
        "#log_reg = LogisticRegression(solver='lbfgs')\n",
        "#log_reg.fit(X_train_imputed, y_train)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs')\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy', log_reg.score(X_val_scaled, y_val))\n",
        "\n",
        "\n"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8470588235294118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTT4KNPcadUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4dc17ab8-14e5-493a-92d2-e29920b2a648"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "model = LogisticRegressionCV(cv=5, n_jobs=-1, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8823529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBQ2XGTgZXA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b6bed4dd-96e4-4b01-bb74-87a8efd6beed"
      },
      "source": [
        "#test data\n",
        "\n",
        "X_test = test[features]\n",
        "y_test = test[target]\n",
        "\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "print('Test Accuracy', model.score(X_test_scaled, y_test))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 0.7894736842105263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jKbOpoVZlf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "32bc1a59-69c6-4505-a065-1b0b9747b5d2"
      },
      "source": [
        "# notes for more fun graphs of value sorted to see top features\n",
        "\n",
        "%matplotlib inline\n",
        "coefficients = pd.Series(model.coef_[0], features)\n",
        "coefficients.sort_values().plot.barh();"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD4CAYAAADYU1DBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}